# @package _global_

# specify here default prediction configuration
defaults:
  - _self_
  - dataset: conll2003
  - pipeline: from_pretrained
  - serializer: json
  - paths: default.yaml
  - extras: default.yaml
  - hydra: default.yaml

pipeline_type: "prediction"

print_config: True

ignore_warnings: True

seed: null

name: "default"

# This should be the value of save_dir from the train config
# or the url to huggingface hub where the taskmodule and model was pushed to.
# It is used in the pipeline config.
model_name_or_path: pie/example-ner-spanclf-conll03
# required for "old" PyTorch-IE models that do not have a pipeline_type key in their config.json.
# Saving a model with AnnotationPipeline.push_to_hub will automatically add this key to the config.json
pipeline:
  pipeline_type: pytorch-ie

# to override model weights with content of a checkpoint
ckpt_path: null

# which split from the loaded dataset will be used
dataset_split: test

## enable this to predict on the first GPU with batch size 32
# pipeline:
#   device: 0
#   batch_size: 32

# if set, the final config including resolved paths etc. will be written to this location
config_out_path: ${paths.prediction_save_dir}/config.yaml
